nam = input('Who are you? ')
print('Welcome, ', nam + '!')
doing = input("How're you doing? ")
if doing == "I'm good": print('Awesome, man!')
else: print("Slacker!")


inp = input('Europe floor? ')
usf = int(inp) + 1
print("US floor:", usf)


rawstr = input("Enter a number: ")
try:
    ival = int(rawstr)
except:
    ival = -1

if ival > 0:
    print("Nice work!")
else:
    print('Dear,', rawstr, "is not a number. Relax and try again.")


a = min(input())
print(a)


print(round(100/9))
print(type(round(100/9)))
print(round(100/9, 2))
print(type(round(100/9, 2)))


# Greeting in your language (a piece)

name = input("What's your name? ")
country = input("What country are you from (print just the name of the country)? ")
def greet(country):
    if country == "Spain":
        return "Hola,"
    else:
        return "Будь верен идее коммунизма,"
print(greet(country), name + "!")


#break - finishes the loop immediately

while True:
    line = input('< ')
    if line == 'done':
        break
    print(line)
print('Done!')


# 'continue' returns to the head of the loop
# 'break' stops the loop execution 

while True:
    line = input('< ')
    if line[0] == '#':    # each if is executed one after another (unlike if - elif - else statement)
        continue          # 'continue' prevents checking the 2nd if in case of # in the beginning of line
    if line == 'done':
        break
    print(line)
print('Done!')
        


for i in [5, 4, 3, 2, 1]:
    print(i, end=" ")
print("\nWe're done")


# Python doesn't understand plural or sing form so the 'i' means the iterable value in the string
# 'i' could be any word I like ('friend' for ex)

friends = ['Vladimir', 'Joseph', 'Iron Felix']
for i in friends:
    print('Happy October Revolution Day,', i + '!')
print('Hooray! ' * 2 + 'HOORAY!!!')


numbers = [45, 75, 2, -2, 3, 94, 5, 34]
# We're going to compare each number with the initially "largest" (i.e. first) number 
# and change the value if the next number is bigger 
largest_number = numbers[0]
for i in numbers:
    if i > largest_number:
        largest_number = i
print('The largest number is:', largest_number)


numbers = [45, 75, 2, -2, 3, 94, 5, 34]
smallest_number = numbers[0]
for i in numbers:
    if i < smallest_number:
        smallest_number = i
print('The smallest number is:', smallest_number)


numbers = [45, 75, 2, -2, 3, 94, 5, 34]

count = 0
smallest_number = numbers[0]
print('Before:', smallest_number)
for i in numbers:
    count = count + 1
    if i < smallest_number:
        smallest_number = i
    print(str(count) + ')', i, smallest_number)
print('After: the smallest number is', smallest_number)


numbers = [45, 75, 2, -2, 3, 94, 5, 34]

smallest_number = None
print('Before:', smallest_number)
for i in numbers:
    if smallest_number is None:
        smallest_number = i
    elif i < smallest_number:
        smallest_number = i
    print(i, smallest_number)
print('After: the smallest number is', smallest_number)


# counting how many times we execute the loop

list = [45, 75, 2, -2, 3, 94, 5, 34]
zork = 0    # count
print('Before', zork)
for i in list:
    zork = zork + 1
    print(str(zork) + ')', i)
print('After', zork)


# we use variable zork to start the calculation (the sum of i in list)

list = [45, 75, 2, -2, 3, 94, 5, 34]
sum = 0
print('Before:', sum)
for i in list:
    sum = sum + i
    print(sum, i)
print('After:', 'sum =', sum)


list = [45, 75, 2, -2, 3, 94, 5, 34]
count = 0
sum = 0
print('Before:', count, sum)
for i in list:
    count = count + 1
    sum = sum + i
    print(str(count) + ')', i)
print('After:', 'sum =', str(sum) + ',', 'average =', sum/count)


lst = [-45, 75, 2, -2, 3, 94, -5, 34, -20]
new_lst = list()
for i in lst:
    if i > 20:
        new_lst.append(i)
print(new_lst)


lst = [-45, 75, 2, -2, 3, 94, -5, 34, -20, -200]
for i in lst:
    if i <= 20:
        print(i)
        lst.remove(i)
print(lst)
print('It doesn\'t work because index is changing with every cycle')


found = False
list = [-45, 75, 2, -2, 3, 94, -5, 34, -20]
for i in list:
    if i == 3:
        found = True
        print(found, i, 'Done')
        break
    print(found, i)


data = "dorothy.gale@mailbox.oz Sat Sept 24"

# searching for @ nsign position
atpos = data.find('@')
print(atpos)

#searching for a space position
sppos = data.find(' ', atpos, 21)
print(sppos)

#extracting the suffix using string slicing
host = data[atpos+1: sppos]
print(host)


fhand = open('mbox-short.txt')

email_list = []
count = 0
total_number = 0

for line in fhand:
    count = count + 1
    if '@' not in line:
        continue
    else:
        atpos = line.find('@')
        sppos = line.find(' ', atpos)
        host = line[atpos+1: sppos]
        host = host.rstrip('>')
        host = host.rstrip('>;')
        host = host.rstrip(';')
        host = host.rstrip(')')
        total_number = total_number + 1
        if host not in email_list:
            email_list.append(host)
#         print('Line', str(count) + ':', host)
print('Found in:', total_number, 'lines')
print('\nEMAIL LIST of', len(email_list), 'adresses:', '\n' + str(email_list))



fhand = open('text.txt', 'r', encoding='utf-8')
for line in fhand:
    #.rstrip() deletes all the \n (newline, i.e. whitespace) characters between the lines
    # which appear during the printing procedure
    line = line.rstrip()
    print(line)


fhand = open('text.txt', 'r', encoding='utf-8')
count = 0
for line in fhand:
    count = count + 1
print('Line Count:', count)


fhand = open('text.txt', 'r', encoding='utf-8')
inp = fhand.read()
print("Characters Count:", len(inp))
print(inp[:26])


fhand = open('text.txt', 'r', encoding='utf-8')
for line in fhand:
    line = line.rstrip()
    if line.startswith("З"):
        print(line)


fhand = open('text.txt', 'r', encoding='utf-8')
for line in fhand:
    line = line.rstrip()
    if not line.startswith("З"):
        continue
    print(line)


fhand = open('text.txt', 'r', encoding='utf-8')
for line in fhand:
    line = line.rstrip()
    if not "в кухне" in line:
        continue
    print(line)


fname = input('Enter the file name: ')
try:
    fhand = open(fname, 'r', encoding='utf-8')
except:
    print('File cannot be opened: "' + fname + '". Try something else.')
    quit()

try:
    count = 0
    for line in fhand:
        count = count + 1
    print('There were', count, 'lines in the "' + fname + '".')
except:
    quit()


print(range(4))


friends = ['Vladimir', 'Joseph', 'the Iron Felix']
print(len(friends))
print(range(len(friends)))


friends = ['Vladimir', 'Joseph', 'Iron Felix']

for friend in friends:
    print('Happy October Revolution Day,', friend + '!')

for i in range(len(friends)):
    friend = friends[i]
    print('Long live,', friend + '!')


x = list()
print(type(x))
print(dir(x))


# first we create an empty list
stuff = list()

# then we start adding the elements using the .append method
stuff.append('the book')
stuff.append(9)
stuff.append(7.4)

# the list stays in order, new elements are added at the end of the list
print(stuff)


list = [45, 75, 2, -2, 3, 94, 5, 34]
9 in list


friends = ['Vladimir', 'Joseph', 'Iron Felix']
friends.sort()
print(friends)
print(friends[0])


# this technique does not use much of memory
# because the loop updates the total with every new input
total = 0
count = 0
while True:
    inp = input("Enter a number: ")
    if inp == 'done' : break
    value = float(inp)
    total = total + value
    count = count + 1
    numlist.append(value)

average = total / count
print('Average:', average)


# it uses more memory because it has to keep all the inputs in memory
numlist = list()
while True:
    inp = input("Enter a number: ")
    if inp == 'done': break
    value = float(inp)
    numlist.append(value)

average = sum(numlist) / len(numlist)
print('Average:', average)


abc = "I can do that"
stuff = abc.split()
print(stuff)
for i in stuff:
    print(i)
print('Length:', len(stuff))
print('stuff[1]:', stuff[1])



fhand = open('text.txt', 'r', encoding='utf-8')
for line in fhand:
    line = line.rstrip()
    if not line.startswith("З"): continue
    words = line.split()
    print(words)


line = "lefthand67@yandex.ru Sat Sept 24"

words = line.split()
print(words)

email = words[0]
print(email)

host = email.split('@')
print(host[1])


new_dict = {}
new_dict['alpha'] = 100
new_dict['beta'] = 'gamma'
print(new_dict)


# counting the frequence of the list elements

host_count = {}
long_list = ['localhost', 'collab.sakaiproject.org', 'iupui.edu', 
             'collab.sakaiproject.org', 'iupui.edu', 'iupui.edu', 
             'umich.edu', 'collab.sakaiproject.org', 'nakamura.uits.iupui.edu', 
             'collab.sakaiproject.org', 'collab.sakaiproject.org']

for name in long_list:
    if name not in host_count:
        host_count[name] = 1
    else:
        host_count[name] = host_count[name] + 1
            
print('\nFREQUENCE of the host names:\n', host_count, '\n\nCheck the .Get Method block for a more convenient techique')



# x is the value, so the value is the same as the dict[key]
# => value = dict[key]

# 1) the loop
if name in host_count:
    x = host_count[name]
else:
    x = 0
        
# 2) GET
    x = host_count.get(name, 0)


host_count = {}
long_list = ['localhost', 'collab.sakaiproject.org', 'iupui.edu', 
             'collab.sakaiproject.org', 'iupui.edu', 'iupui.edu', 
             'umich.edu', 'collab.sakaiproject.org', 'nakamura.uits.iupui.edu', 
             'collab.sakaiproject.org', 'collab.sakaiproject.org']

for name in long_list:
    host_count[name] = host_count.get(name, 0) + 1  # dict[name] is just the value, expressed in the different form
            
print('\nFREQUENCE of the host names:\n', host_count)



counts = {}
# You can type input('Enter the file name: ') instead of 'text.txt'
fhand = open('text.txt', 'r', encoding='utf-8')
for line in fhand:
    line = line.rstrip() and line.lower()
    words = line.split()    
#     print('Words:', words)
    for word in words:
        word = word.strip(',')
        word = word.strip('.')
        word = word.strip(';')
        word = word.strip('?')
        word = word.strip('!')
        word = word.strip('?!')
        word = word.strip('...')
        word = word.strip('"')
        word = word.strip(':')
        word = word.strip('(')
        word = word.strip(')')
        counts[word] = counts.get(word, 0) + 1
# print('Length: ', len(counts), '\nCounts:', counts)

print('Move to the next cell')


# !Run the previous cell before

largest_count = 0
most_freq_word = ''
for word, count in counts.items():
    if count > largest_count:
        largest_count = count        
#         print(largest_count, word)
#     print(count, word)            
print('Count: {}'.format(largest_count))

freq_words = []
for word, count in counts.items():
    if (count == largest_count) and (word not in freq_words):
        freq_words.append(word)
print('Quantity of words:', len(freq_words), '\nList of most frequent words:\n', freq_words)


jjj = {'chuck': 1, 'fred': 42, 'jan': 100, '19': 19, 26: 72}
print('list(jjj):', list(jjj))
print(jjj.keys())
print(jjj.values())
print(jjj.items(), '<= these are the tuples')

for key, value in jjj.items():
    try:
        key = float(key)
        continue
    except:
        print(key)


# dfile = input('Enter the default file name to make your life easier: ')  # activate for a script

def most_freq_word():

    """
    The Most Frequent Word Function
    searches for the most frequent word(s) in the document with disregard to the case of 
    the letters in words. 
    It shows the "Largest count" number (i.e. value in dictionary) and lists all 
    the words (keys) that are complemented to the value.
    
    The function ignores the strings that can be converted to floats and integers. 
    
    NOTE! You can reassign the default file in prompt by activating the line above the function code
    and deactivating the first line of the function.
    
    >>> Example:
    
    Enter the file name (press Enter to open the default file): 
    Opened by default: mbox-short.txt

    Largest count: 352
    jan

    Quantity of words: 1
    Most frequent words: ['jan'] <<<
    
    """

    dfile = 'mbox-short.txt'  # a file that be opened by default (Enter button), deactivate when using as script

    fname = input('Enter the file name (press Enter to open the default file): ')
    if len(fname) < 1:
        fname = dfile
        print('Opened by default:', dfile)
    fhand = open(fname, 'r', encoding='utf-8')

    counts = {}
    for line in fhand:
        line = line.rstrip() and line.lower()
        words = line.split()
    #     print('Words:', words)
        for word in words:
            word = word.strip(',')
            word = word.strip('.')
            word = word.strip(';')
            word = word.strip('?')
            word = word.strip('!')
            word = word.strip('?!')
            word = word.strip('"')
            word = word.strip(':')
            word = word.strip('(')
            word = word.strip(')')
            word = word.strip('[')
            word = word.strip(']')
            try:                        # the operation filters ints and floats
                word = float(word)
                continue
            except ValueError:           # we get only non-ints and non-floats in counts list
                if len(word) > 0:
                    counts[word] = counts.get(word, 0) + 1
    # print('\nLength: {}\nCounts: {}'.format(len(counts),counts))

    largest_count = None                # searching for the largest value (i.e. count of the words)
    # print('\nLargest count search:')  # got be activated only with print(count, word)
    for word, count in counts.items():
        if largest_count is None or count > largest_count:
            largest_count = count
    #         print(largest_count, word)
    #     print(count, word)
    print('\nLargest count: {}'.format(largest_count))

    freq_words = []                     # most frequent words' list
    for word, count in counts.items():
        if (count == largest_count) and (word not in freq_words):
            freq_words.append(word)
            # print(word)
    return '\nQuantity of words: {}\nMost frequent words: {}.\nDone'.format(len(freq_words), freq_words)



print(most_freq_word())


(x, y) = (4, 'Fred')
print(y)


x, y = 4, 'Fred'
print(x)


l = list()
dir(l)


t = tuple()
dir(t)


(0, 1, 2) < (5, 2, 1)


('Jones', 'Sally') < ('Jones', 'Sam')


('Jones', 'Sally') == ('Jones', 'Sam')


d = {'a': 10, 'b':1, 'c':22}
print(d.items())
print(sorted(d.items()), '\n')

for k, v in sorted(d.items()):
    print(k, v)


c = {'a': 10, 'b':1, 'c':22}

tmp = list()
for key, val in c.items():
    tmp.append( (val, key) )
print(tmp)

tmp = sorted(tmp, reverse=True)
print(tmp)


c = {'a': 10, 'b':1, 'c':22}

print( sorted( [ (v, k) for k, v in c.items() ], reverse=True ) )


with open('text.txt', 'r', encoding='utf-8') as fhand:  # context manager to close the file when done
    counts = dict()
    for line in fhand:
        line = line.rstrip() and line.lower()
        words = line.split()
        for word in words:
            if word.isalpha():
                counts[word] = counts.get(word, 0) + 1

lst = sorted( [(val, key) for key, val in counts.items()], reverse=True )

for val, key in lst[:10]:
    print(f'{key} - {val}', end='; ')


fhand = open('mbox-short.txt')
for line in fhand:
    line = line.rstrip()
    if line.find('From:') >= 0:
        print(line)


import re

fhand = open('mbox-short.txt')
for line in fhand:
    line = line.rstrip()
    if re.search('From:', line):
        print(line)


fhand = open('mbox-short.txt')
for line in fhand:
    line = line.rstrip()
    if line.startswith('From:'):
        print(line)


import re

fhand = open('mbox-short.txt')
for line in fhand:
    line = line.rstrip()
    if re.search('^From:', line):
        print(line)


import re

fhand = open('mbox-short.txt')
for line in fhand:
    line = line.rstrip()
    if re.search('^X.*:', line):
        print(line)


import re

fhand = open('mbox-short.txt')
for line in fhand:
    line = line.rstrip()
    if re.search('^X-A\S+:', line):
        print(line)


import re
x = 'My 2 favourite numbers are 19 and 42. Today is 2022'
y = re.findall('[0-9]+', x)
print(y)


import re
x = 'My 2 favourite numbers are 19 and 42. Today is 2022'
y = re.findall('[AEIOU]+', x)
print(y)


import re
x = 'From: Using the : character'
y = re.findall('^F.+:', x)
print(y)


import re
x = 'From: Using the : character'
y = re.findall('^F.+?:', x)
print(y)


import re
x = 'From stephen.marquard@uct.ac.za Sat Jan  5 09:14:16 2008'
y = re.findall('\S+@\S+', x)
print(y)


import re
x = 'From stephen.marquard@uct.ac.za Sat Jan  5 09:14:16 2008'
y = re.findall('^From (\S+@\S+)', x)
print(y)


data = "From stephen.marquard@uct.ac.za Sat Jan  5 09:14:16 2008"

# searching for @ nsign position
atpos = data.find('@')
print(atpos)

#searching for a space position
sppos = data.find(' ', atpos)
print(sppos)

#extracting the suffix using string slicing
host = data[atpos+1 : sppos]
print(host)


line = 'From stephen.marquard@uct.ac.za Sat Jan  5 09:14:16 2008'

words = line.split()
print(words)

email = words[1]
print(email)

host = email.split('@')
print(host[1])


import re

line = 'From stephen.marquard@uct.ac.za Sat Jan  5 09:14:16 2008'
y = re.findall('@([^ ]*)', line)
print(y)


# my example - why isn't it better?
import re
line = 'From stephen.marquard@uct.ac.za Sat Jan  5 09:14:16 2008'
y = re.findall('@(\S+)', line)
print(y)


lin = 'From stephen.marquard@uct.ac.za Sat Jan  5 09:14:16 2008'
y = re.findall('^From .*@([^ ]*)', lin)
print(y)


import re
fhand = open('mbox-short.txt')
numlist = list()
for line in fhand:
    line = line.rstrip()
    stuff = re.findall('^X-DSPAM-Confidence: ([0-9.]+)', line)
    if len(stuff)!=1: continue
    num = float(stuff[0])
    numlist.append(num)
print(numlist)
print('Maximum:', max(numlist))



import re
a = 'We just got $10.000 in a lottery winning'
y = re.findall('\$[0-9.]+', a)
print(y)


import re
s = 'A message from csev@umich.edu to cwen@iupui.edu about meeting @2PM'
lst = re.findall('\\S@\\S+', s)
print(lst)


import urllib.request, urllib.parse, urllib.error

url = 'https://rustih.ru/aleksandr-pushkin-ya-pomnyu-chudnoe-mgnovene/'
fhand = urllib.request.urlopen(url)
for line in fhand:
    print(line.decode().strip())


import urllib.request, urllib.parse, urllib.error

url = 'https://rustih.ru/aleksandr-pushkin-ya-pomnyu-chudnoe-mgnovene/'
fhand = urllib.request.urlopen(url)

counts = dict()
for line in fhand:
    words = line.decode().split()
    for word in words:
        counts[word] = counts.get(word, 0)+1
print(counts)


import urllib.request, urllib.parse, urllib.error
from bs4 import BeautifulSoup
import ssl

# Ignore SSL certificate errors
ctx = ssl.create_default_context()
ctx.check_hostname = False
ctx.verify_mode = ssl.CERT_NONE

url = 'https://rustih.ru/aleksandr-pushkin-ya-pomnyu-chudnoe-mgnovene/'
html = urllib.request.urlopen(url, context=ctx).read()
soup = BeautifulSoup(html, 'html.parser')

# Retrieve all of the anchor tags
tags = soup('a')
for tag in tags:
    print(tag.get('href', None))


import urllib.request, urllib.parse, urllib.error
from bs4 import BeautifulSoup
import ssl

# Ignore SSL certificate errors
ctx = ssl.create_default_context()
ctx.check_hostname = False
ctx.verify_mode = ssl.CERT_NONE

url = 'https://rustih.ru/aleksandr-pushkin-ya-pomnyu-chudnoe-mgnovene/'
html = urllib.request.urlopen(url, context=ctx).read()
soup = BeautifulSoup(html, 'html.parser')

# Retrieve all of the anchor tags
tags = soup('p')
for tag in tags:
    print(tag.get_text())


from urllib.request import urlopen
from bs4 import BeautifulSoup
url = "https://rustih.ru/aleksandr-pushkin-ya-pomnyu-chudnoe-mgnovene/"
html = urlopen(url).read()
soup = BeautifulSoup(html, features="html.parser")

# kill all script and style elements
for script in soup(["script", "style"]):
    script.extract()    # rip it out
    
# get text
text = soup.get_text()

# break into lines and remove leading and trailing space on each
lines = (line.strip() for line in text.splitlines())

# break multi-headlines into a line each
chunks = (phrase.strip() for line in lines for phrase in line.split("  "))

# drop blank lines
text = '\n'.join(chunk for chunk in chunks if chunk)
print(text)


import xml.etree.ElementTree as ET

data = '''
<person>
  <name>Chuck</name>
  <phone type="intl">
    +1 734 303 4456
  </phone>
  <email hide="yes" />
</person>'''

tree = ET.fromstring(data)
print('Name:', tree.find('name').text)
print('Attr:', tree.find('email').get('hide'))


import xml.etree.ElementTree as ET

input = '''
<stuff>
  <users>
    <user x="2">
      <id>001</id>
      <name>Chuck</name>
    </user>
    <user x="7">
      <id>009</id>
      <name>Brent</name>
    </user>
  </users>
</stuff>'''

stuff = ET.fromstring(input)
lst = stuff.findall('users/user')
print('User count:', len(lst))

for item in lst:
    print('Name', item.find('name').text)
    print('Id', item.find('id').text)
    print('Attribute', item.get('x'))


# dictionary

import json

data = '''
{
  "name" : "Chuck",
  "phone" : {
    "type" : "intl",
    "number" : "+1 734 303 4456"
   },
   "email" : {
     "hide" : "yes"
   }
}'''

info = json.loads(data)
print('Name:', info["name"])
print('Hide:', info["email"]["hide"])


# list

import json

data = '''
[
  { "id" : "001",
    "x" : "2",
    "name" : "Chuck"
  } ,
  { "id" : "009",
    "x" : "7",
    "name" : "Brent"
  }
]'''

info = json.loads(data)
print('User count:', len(info))

for item in info:
    print('Name', item['name'])
    print('Id', item['id'])
    print('Attribute', item['x'])


import urllib.request, urllib.parse, urllib.error
import json
import ssl

api_key = False
# If you have a Google Places API key, enter it here
# api_key = 'AIzaSy___IDByT70'
# https://developers.google.com/maps/documentation/geocoding/intro

if api_key is False:
    api_key = 42
    serviceurl = 'http://py4e-data.dr-chuck.net/json?'
else :
    serviceurl = 'https://maps.googleapis.com/maps/api/geocode/json?'

# Ignore SSL certificate errors
ctx = ssl.create_default_context()
ctx.check_hostname = False
ctx.verify_mode = ssl.CERT_NONE

while True:
    address = input('Enter location: ')
    if len(address) < 1: break

    parms = dict()
    parms['address'] = address
    if api_key is not False: parms['key'] = api_key
    url = serviceurl + urllib.parse.urlencode(parms)

    print('Retrieving', url)
    uh = urllib.request.urlopen(url, context=ctx)
    data = uh.read().decode()
    print('Retrieved', len(data), 'characters')

    try:
        js = json.loads(data)
    except:
        js = None

    if not js or 'status' not in js or js['status'] != 'OK':
        print('==== Failure To Retrieve ====')
        print(data)
        continue

    print(json.dumps(js, indent=4))

    lat = js['results'][0]['geometry']['location']['lat']
    lng = js['results'][0]['geometry']['location']['lng']
    print('lat', lat, 'lng', lng)
    location = js['results'][0]['formatted_address']
    print(location)


{
   "results" : [
      {
         "address_components" : [
            {
               "long_name" : "Kokshetau",
               "short_name" : "Kokshetau",
               "types" : [ "locality", "political" ]
            },
            {
               "long_name" : "Zerendi District",
               "short_name" : "Zerendi District",
               "types" : [ "administrative_area_level_2", "political" ]
            },
            {
               "long_name" : "Akmola Province",
               "short_name" : "Akmola Province",
               "types" : [ "administrative_area_level_1", "political" ]
            },
            {
               "long_name" : "Kazakhstan",
               "short_name" : "KZ",
               "types" : [ "country", "political" ]
            },
            {
               "long_name" : "020000",
               "short_name" : "020000",
               "types" : [ "postal_code" ]
            }
         ],
         "formatted_address" : "Kokshetau 020000, Kazakhstan",
         "geometry" : {
            "bounds" : {
               "northeast" : {
                  "lat" : 53.3444028,
                  "lng" : 69.4638061
               },
               "southwest" : {
                  "lat" : 53.2518123,
                  "lng" : 69.3523467
               }
            },
            "location" : {
               "lat" : 53.2871307,
               "lng" : 69.40444939999999
            },
            "location_type" : "APPROXIMATE",
            "viewport" : {
               "northeast" : {
                  "lat" : 53.3444028,
                  "lng" : 69.4638061
               },
               "southwest" : {
                  "lat" : 53.2518123,
                  "lng" : 69.3523467
               }
            }
         },
         "partial_match" : True,
         "place_id" : "ChIJVy5JP2CUTEIRE1RU19YiGYg",
         "types" : [ "locality", "political" ]
      }
   ],
   "status" : "OK"
}


import sqlite3
conn = sqlite3.connect('emaildb.sqlite')
cur = conn.cursor()

cur.execute('DROP TABLE IF EXISTS Counts')

cur.execute('''
CREATE TABLE Counts (email TEXT, Count INTEGER)''')

fname = input('Enter file name: ')
if (len(fname)<1): fname = 'mbox-short.txt'
with open(fname) as fh:
    counter = 0
    for line in fh:
        if not line.startswith('From: '): continue
        pieces = line.split()
        email = pieces[1]
        cur.execute('SELECT count FROM Counts WHERE email = ? ', (email,))
        row = cur.fetchone()
        if row is None:
            cur.execute('''INSERT INTO Counts (email, count)
                    VALUES (?, 1)''', (email,))
        else:
            cur.execute('UPDATE Counts SET count = count + 1 WHERE email = ?', (email,))
        counter+=1
        if counter%100 == 0:
            conn.commit()  # commit takes a lot of time, it's better to commit every 10th time, for ex.
    
# https://www.sqlite.org/lang_select.html
sqlstr = 'SELECT email, count FROM Counts ORDER BY count DESC LIMIT 10'

for row in cur.execute(sqlstr):
    print(str(row[0]), row[1])
    
cur.close()
print('Closed')


conn = sqlite3.connect('emaildb.sqlite')
cur = conn.cursor()
conn.close()
print('Closed')


# Primary Key integers will be inserted automatically (AUTOINCREMENT)
CREATE TABLE "Artist" (
    "id" INTEGER PRIMARY KEY AUTOINCREMENT NOT NULL UNIQUE, 
    "name" TEXT
)

# "artist_id" is Foreign Key and "title" is the Logical Key
CREATE TABLE "Album" (
    "id" INTEGER PRIMARY KEY AUTOINCREMENT NOT NULL UNIQUE, 
    "artist_id" INTEGER,
    "title" TEXT
)

CREATE TABLE "Genre" (
    "id" INTEGER PRIMARY KEY AUTOINCREMENT NOT NULL UNIQUE, 
    "name" TEXT
)

# Here are two FK: "album_id" and "genre_id" 
# That's why this table will be filled last, when all the other tables are filled
CREATE TABLE "Track" (
    "id" INTEGER PRIMARY KEY AUTOINCREMENT NOT NULL UNIQUE, 
    "title" TEXT,  
    "album_id" INTEGER, 
    "genre_id" INTEGER, 
    len INTEGER, rating INTEGER, "count" INTEGER
)

INSERT INTO Artist (name) VALUES ('Led Zeppelin') ;
INSERT INTO Artist (name) VALUES ('AC/DC') ;

INSERT INTO Genre (name) VALUES ('Rock') ;
INSERT INTO Genre (name) VALUES ('Metal');

# Here we put the FK "artist_id" that we already know
INSERT INTO Album (title, artist_id) VALUES ('Who Made Who', 2);
INSERT INTO Album (title, artist_id) VALUES ('IV', 1);

INSERT INTO Track (title, rating, len, count, album_id, genre_id) 
    VALUES ('Black Dog', 5, 297, 0, 2, 1) ;
INSERT INTO Track (title, rating, len, count, album_id, genre_id) 
    VALUES ('Stairway to Heaven', 5, 482, 0, 2, 1) ;
INSERT INTO Track (title, rating, len, count, album_id, genre_id) 
    VALUES ('About to Rock', 5, 313, 0, 1, 2) ;
INSERT INTO Track (title, rating, len, count, album_id, genre_id) 
    VALUES ('Who Made Who', 5, 207, 0, 1, 2) ;


SELECT Album.title, Artist.name 
    FROM Album JOIN Artist 
    ON Album.artist_id = Artist.id

SELECT Album.title, Album.artist_id, Artist.id, Artist.name 
    FROM Album JOIN Artist 
    ON Album.artist_id = Artist.id


SELECT Track.title, Track.genre_id, Genre.id, Genre.name 
    FROM Track JOIN Genre

# Compare to this
SELECT Track.title, Track.genre_id, Genre.id, Genre.name 
    FROM Track JOIN Genre
    ON Track.genre_id = Genre.id

SELECT Track.title, Genre.name 
    FROM Track JOIN Genre 
    ON Track.genre_id = Genre.id


SELECT Track.title, Artist.name, Album.title, Genre.name 
    FROM Track JOIN Genre JOIN Album JOIN Artist 
    ON Track.genre_id = Genre.id 
    AND Track.album_id = Album.id 
    AND Album.artist_id = Artist.id


import xml.etree.ElementTree as ET
import sqlite3

conn = sqlite3.connect('trackdb.sqlite')
# using context manager prevents db blocking
with conn:
    cur = conn.cursor()

    # Make some fresh tables using executescript()
    cur.executescript('''
    DROP TABLE IF EXISTS Artist;
    DROP TABLE IF EXISTS Album;
    DROP TABLE IF EXISTS Track;

    CREATE TABLE Artist (
        id INTEGER NOT NULL PRIMARY KEY AUTOINCREMENT UNIQUE,
        name TEXT UNIQUE
    );

    CREATE TABLE Album (
        id INTEGER NOT NULL PRIMARY KEY AUTOINCREMENT UNIQUE,
        artist_id INTEGER,
        title TEXT UNIQUE
    );

    CREATE TABLE Track (
        id INTEGER NOT NULL PRIMARY KEY AUTOINCREMENT UNIQUE,
        title TEXT UNIQUE,
        album_id INTEGER,
        len INTEGER, rating INTEGER, count INTEGER
    );
    ''')

    fname = input('Enter file name: ')
    if len(fname)<1: fname = 'tracks_library.xml'

    # <key>Track ID</key><integer>369</integer>
    # <key>Name</key><string>Another One Bites The Dust</string>
    # <key>Artist</key><string>Queen</string>
    def lookup(d, key):
        found = False
        for child in d:
            if found: return child.text
            if child.tag == 'key' and child.text == key:
                found = True
        return None

    stuff = ET.parse(fname)
    all = stuff.findall('dict/dict/dict')  # we need embedded dictionaries
    print('Dict count:', len(all))

    comcount = 0  # counter for commits
    for entry in all:
        if (lookup(entry, 'Track ID')) is None: continue

        name = lookup(entry, 'Name')
        artist = lookup(entry, 'Artist')
        album = lookup(entry, 'Album')
        count = lookup(entry, 'Play Count')
        rating = lookup(entry, 'Rating')
        length = lookup(entry, 'Total Time')

        if name is None or artist is None or album is None:
            continue

        print(name, artist, album, count, rating, length)

        cur.execute('''INSERT OR IGNORE INTO Artist (name)
            VALUES (?)''', (artist,))
        cur.execute('SELECT id FROM Artist WHERE name=?', (artist,))
        artist_id = cur.fetchone()[0]

        cur.execute('''INSERT OR IGNORE INTO Album (title, artist_id)
            VALUES (?, ?)''', (album, artist_id))
        cur.execute('SELECT id FROM Album WHERE title=?', (album,))
        album_id = cur.fetchone()[0]

        cur.execute('''INSERT OR REPLACE 
            INTO Track (title, album_id, len, rating, count)
            VALUES (?, ?, ?, ?, ?)''',
            (name, album_id, length, rating, count))

        comcount+=1
        if comcount%100 == 0:
            conn.commit()



CREATE TABLE User (
    id     INTEGER NOT NULL PRIMARY KEY AUTOINCREMENT UNIQUE,
    name   TEXT UNIQUE,
    email  TEXT
) ;

CREATE TABLE Course (
    id     INTEGER NOT NULL PRIMARY KEY AUTOINCREMENT UNIQUE,
    title  TEXT UNIQUE
) ;

CREATE TABLE Member (
    user_id     INTEGER,
    course_id   INTEGER,
    role        INTEGER,
    PRIMARY KEY (user_id, course_id)
) ;


INSERT INTO User (name, email) VALUES ('Jane', 'jane@tsugi.org');
INSERT INTO User (name, email) VALUES ('Ed', 'ed@tsugi.org');
INSERT INTO User (name, email) VALUES ('Sue', 'sue@tsugi.org');

INSERT INTO Course (title) VALUES ('Python');
INSERT INTO Course (title) VALUES ('SQL');
INSERT INTO Course (title) VALUES ('PHP');

INSERT INTO Member (user_id, course_id, role) VALUES (1, 1, 1);
INSERT INTO Member (user_id, course_id, role) VALUES (2, 1, 0);
INSERT INTO Member (user_id, course_id, role) VALUES (3, 1, 0);

INSERT INTO Member (user_id, course_id, role) VALUES (1, 2, 0);
INSERT INTO Member (user_id, course_id, role) VALUES (2, 2, 1);

INSERT INTO Member (user_id, course_id, role) VALUES (2, 3, 1);
INSERT INTO Member (user_id, course_id, role) VALUES (3, 3, 0);

SELECT User.name, Member.role, Course.title
  FROM User JOIN Member JOIN Course
  ON Member.user_id = User.id AND Member.course_id = Course.id
  ORDER BY Course.title, Member.role DESC, User.name 


import json
import sqlite3

conn = sqlite3.connect('rosterdb.sqlite')
with conn:
    cur = conn.cursor()
    
    # Do some setup
    cur.executescript('''
    DROP TABLE IF EXISTS User;
    DROP TABLE IF EXISTS Member;
    DROP TABLE IF EXISTS Course;
    
    CREATE TABLE User (
        id INTEGER NOT NULL PRIMARY KEY AUTOINCREMENT UNIQUE,
        name TEXT UNIQUE
    );
        
        
    CREATE TABLE Course (
        id INTEGER NOT NULL PRIMARY KEY AUTOINCREMENT UNIQUE,
        title TEXT UNIQUE
    );
        
    CREATE TABLE Member (
        user_id   INTEGER,
        course_id INTEGER,
        role      INTEGER,
        PRIMARY KEY (user_id, course_id)
    )
    ''')

    fname = input('Enter file name: ')
    if len(fname)<1: fname = 'roster_data_sample.json'
    
    # [
    #   [ "Charley", "si110", 1 ],
    #   [ "Mea", "si110", 0 ],
    
    with open(fname) as data:
        str_data = data.read()
        json_data = json.loads(str_data)
        
        comcount = 0  # counter for commits
        for entry in json_data:
            
            name = entry[0]
            title = entry[1]
            role = entry[2]
            
            # print((name, title))
            
            cur.execute('INSERT OR IGNORE INTO User (name) VALUES ( ? )', ( name, ) )
            cur.execute('SELECT id FROM User WHERE name = ?', ( name, ) )
            # we fetch the first element in case there are more than one elements in cur
            user_id = cur.fetchone()[0]
            
            cur.execute('INSERT OR IGNORE INTO Course (title) VALUES ( ? )', ( title, ) )
            cur.execute('SELECT id FROM Course WHERE title = ? ', ( title, ))
            course_id = cur.fetchone()[0]

            cur.execute('INSERT OR REPLACE INTO Member (user_id, course_id, role) VALUES ( ?, ?, ? )',
            ( user_id, course_id,  role) )
            
            comcount+=1
            if comcount%50 == 0:
                conn.commit()

print(comcount, 'entries processed')
print('Done')



SELECT User.name, Course.title 
    FROM User JOIN Course
    ON Member.user_id = User.id
    AND Member.course_id = Course.id


# Keep this file separate

# https://apps.twitter.com/
# Create new App and get the four strings

def oauth():
    return {"consumer_key": "h7Lu...Ng",
            "consumer_secret": "dNKenAC3New...mmn7Q",
            "token_key": "10185562-eibxCp9n2...P4GEQQOSGI",
            "token_secret": "H0ycCFemmC4wyf1...qoIpBo"}


import urllib.request, urllib.parse, urllib.error
import twurl
import json
import sqlite3
import ssl

TWITTER_URL = 'https://api.twitter.com/1.1/friends/list.json'

conn = sqlite3.connect('friends.sqlite')
cur = conn.cursor()

cur.execute('''CREATE TABLE IF NOT EXISTS People
            (id INTEGER PRIMARY KEY, name TEXT UNIQUE, retrieved INTEGER)''')
cur.execute('''CREATE TABLE IF NOT EXISTS Follows
            (from_id INTEGER, to_id INTEGER, UNIQUE(from_id, to_id))''')

# Ignore SSL certificate errors
ctx = ssl.create_default_context()
ctx.check_hostname = False
ctx.verify_mode = ssl.CERT_NONE

while True:
    acct = input('Enter a Twitter account, or quit: ')
    if (acct == 'quit'): break
    if (len(acct) < 1):
        cur.execute('SELECT id, name FROM People WHERE retrieved=0 LIMIT 1')
        try:
            (id, acct) = cur.fetchone()
        except:
            print('No unretrieved Twitter accounts found')
            continue
    else:
        cur.execute('SELECT id FROM People WHERE name = ? LIMIT 1',
                    (acct, ))
        try:
            id = cur.fetchone()[0]
        except:
            cur.execute('''INSERT OR IGNORE INTO People
                        (name, retrieved) VALUES (?, 0)''', (acct, ))
            conn.commit()
            if cur.rowcount != 1:
                print('Error inserting account:', acct)
                continue
            id = cur.lastrowid

    url = twurl.augment(TWITTER_URL, {'screen_name': acct, 'count': '100'})
    print('Retrieving account', acct)
    try:
        connection = urllib.request.urlopen(url, context=ctx)
    except Exception as err:
        print('Failed to Retrieve', err)
        break

    data = connection.read().decode()
    headers = dict(connection.getheaders())

    print('Remaining', headers['x-rate-limit-remaining'])

    try:
        js = json.loads(data)
    except:
        print('Unable to parse json')
        print(data)
        break

    # Debugging
    # print(json.dumps(js, indent=4))

    if 'users' not in js:
        print('Incorrect JSON received')
        print(json.dumps(js, indent=4))
        continue

    cur.execute('UPDATE People SET retrieved=1 WHERE name = ?', (acct, ))

    countnew = 0
    countold = 0
    for u in js['users']:
        friend = u['screen_name']
        print(friend)
        cur.execute('SELECT id FROM People WHERE name = ? LIMIT 1',
                    (friend, ))
        try:
            friend_id = cur.fetchone()[0]
            countold = countold + 1
        except:
            cur.execute('''INSERT OR IGNORE INTO People (name, retrieved)
                        VALUES (?, 0)''', (friend, ))
            conn.commit()
            if cur.rowcount != 1:
                print('Error inserting account:', friend)
                continue
            friend_id = cur.lastrowid
            countnew = countnew + 1
        cur.execute('''INSERT OR IGNORE INTO Follows (from_id, to_id)
                    VALUES (?, ?)''', (id, friend_id))
    print('New accounts=', countnew, ' revisited=', countold)
    print('Remaining', headers['x-rate-limit-remaining'])
    conn.commit()
cur.close()


# Geoload.py

import urllib.request, urllib.parse, urllib.error
import http
import sqlite3
import json
import time
import ssl
import sys

api_key = False
# If you have a Google Places API key, enter it here
# api_key = 'AIzaSy___IDByT70'

if api_key is False:
    api_key = 42
    service_url = "http://py4e-data.dr-chuck.net/json?"
else :
    serviceurl = "https://maps.googleapis.com/maps/api/geocode/json?"
    
# Additional detail for urllib
# http.client.HTTPConnection.debuglevel = 1

conn = sqlite3.connect('/Geodata/geoadta.sqlite')
cur = conn.cursor()

cur.execute('CREATE TABLE IF NOT EXISTS Locations (addresses TEXT, geodata TEXT)')

# Ignore SSL certificate errors
ctx = ssl.create_default_context()
ctx.check_hostname = False
ctx.verify_mode = ssl.CERT_NONE

with open('/Geodata/where.data') as fh:
    comcount = 0
    count= 0
    for line in fh:
        if count > 200:
            print('Retrieved 200 locations, restart to retrieve more')
            break
        
        address = line.strip()
        print('')
        cur.execute("SELECT geodata FROM Locations WHERE address= ?", (memoryview(address.encode()), ))
        
        try:
            data = cur.fetchone()[0]
            print("Found in database", address)
            continue
        except:
            pass
        
        parms = dict()
        parms["address"] = address
        if api_key is not False: parms['key'] = api_key
        url = serviceurl + urllib.parse.urlencode(parms)
        
        print('Retrieving', url)
        uh = urllib.request.urlopen(url, context=ctx)
        data = uh.read().decode()
        print('Retrieved', len(data), 'characters', data[:20].replace('\n', ' '))
        count+=1
        
        try:
            js = json.loads(data)
        except:
            print(data)  # We print in case unicode causes an error
            continue
        
        if 'status' not in js or (js['status'] != 'OK' and js['status'] != 'ZERO_RESULTS'):
            print('==== Failure To Retrieve ====')
            print(data)
            break
        
        cur.execute('''INSERT INTO Locations (address, geodata) 
                VALUES ( ?, ? )''', (memoryview(address.encode()), memoryview(data.encode()) ) )
        
        comcount+=1
        if comcount % 50 == 0:
            conn.commit()
        if count % 10 == 0:
            print('Pausing for a bit...')
            time.sleep(5)

print("Run geodump.py to read the data from the database so you can vizualize it on a map.")


# geodump.py

import sqlite3
import json
import codecs

conn = sqlite3.connect('geodata.sqlite')
cur = conn.cursor()

cur.execute('SELECT * FROM Locations')
fhand = codecs.open('where.js', 'w', "utf-8")
fhand.write("myData = [\n")
count = 0
for row in cur :
    data = str(row[1].decode())
    try: js = json.loads(str(data))
    except: continue

    if not('status' in js and js['status'] == 'OK') : continue

    lat = js["results"][0]["geometry"]["location"]["lat"]
    lng = js["results"][0]["geometry"]["location"]["lng"]
    if lat == 0 or lng == 0 : continue
    where = js['results'][0]['formatted_address']
    where = where.replace("'", "")
    try :
        print(where, lat, lng)

        count = count + 1
        if count > 1 : fhand.write(",\n")
        output = "["+str(lat)+","+str(lng)+", '"+where+"']"
        fhand.write(output)
    except:
        continue

fhand.write("\n];\n")
cur.close()
fhand.close()
print(count, "records written to where.js")
print("Open where.html to view the data in a browser")



import sqlite3
import urllib.error
import ssl
from urllib.parse import urljoin
from urllib.parse import urlparse
from urllib.request import urlopen
from bs4 import BeautifulSoup

# Ignore SSL certificate errors
ctx = ssl.create_default_context()
ctx.check_hostname = False
ctx.verify_mode = ssl.CERT_NONE

conn = sqlite3.connect('spider.sqlite')
cur = conn.cursor()

cur.execute('''CREATE TABLE IF NOT EXISTS Pages
    (id INTEGER PRIMARY KEY, url TEXT UNIQUE, html TEXT,
     error INTEGER, old_rank REAL, new_rank REAL)''')

cur.execute('''CREATE TABLE IF NOT EXISTS Links
    (from_id INTEGER, to_id INTEGER, UNIQUE(from_id, to_id))''')

cur.execute('''CREATE TABLE IF NOT EXISTS Webs (url TEXT UNIQUE)''')

# Check to see if we are already in progress...
cur.execute('SELECT id,url FROM Pages WHERE html is NULL and error is NULL ORDER BY RANDOM() LIMIT 1')
row = cur.fetchone()
if row is not None:
    print("Restarting existing crawl.  Remove spider.sqlite to start a fresh crawl.")
else :
    starturl = input('Enter web url or enter: ')
    if ( len(starturl) < 1 ) : starturl = 'http://www.dr-chuck.com/'
    if ( starturl.endswith('/') ) : starturl = starturl[:-1]
    web = starturl
    if ( starturl.endswith('.htm') or starturl.endswith('.html') ) :
        pos = starturl.rfind('/')
        web = starturl[:pos]

    if ( len(web) > 1 ) :
        cur.execute('INSERT OR IGNORE INTO Webs (url) VALUES ( ? )', ( web, ) )
        cur.execute('INSERT OR IGNORE INTO Pages (url, html, new_rank) VALUES ( ?, NULL, 1.0 )', ( starturl, ) )
        conn.commit()

# Get the current webs
cur.execute('''SELECT url FROM Webs''')
webs = list()
for row in cur:
    webs.append(str(row[0]))

print(webs)

many = 0
while True:
    if ( many < 1 ) :
        sval = input('How many pages:')
        if ( len(sval) < 1 ) : break
        many = int(sval)
    many = many - 1

    cur.execute('SELECT id,url FROM Pages WHERE html is NULL and error is NULL ORDER BY RANDOM() LIMIT 1')
    try:
        row = cur.fetchone()
        # print row
        fromid = row[0]
        url = row[1]
    except:
        print('No unretrieved HTML pages found')
        many = 0
        break

    print(fromid, url, end=' ')

    # If we are retrieving this page, there should be no links from it
    cur.execute('DELETE from Links WHERE from_id=?', (fromid, ) )
    try:
        document = urlopen(url, context=ctx)

        html = document.read()
        if document.getcode() != 200 :
            print("Error on page: ",document.getcode())
            cur.execute('UPDATE Pages SET error=? WHERE url=?', (document.getcode(), url) )

        if 'text/html' != document.info().get_content_type() :
            print("Ignore non text/html page")
            cur.execute('DELETE FROM Pages WHERE url=?', ( url, ) )
            conn.commit()
            continue

        print('('+str(len(html))+')', end=' ')

        soup = BeautifulSoup(html, "html.parser")
    except KeyboardInterrupt:
        print('')
        print('Program interrupted by user...')
        break
    except:
        print("Unable to retrieve or parse page")
        cur.execute('UPDATE Pages SET error=-1 WHERE url=?', (url, ) )
        conn.commit()
        continue

    cur.execute('INSERT OR IGNORE INTO Pages (url, html, new_rank) VALUES ( ?, NULL, 1.0 )', ( url, ) )
    cur.execute('UPDATE Pages SET html=? WHERE url=?', (memoryview(html), url ) )
    conn.commit()

    # Retrieve all of the anchor tags
    tags = soup('a')
    count = 0
    for tag in tags:
        href = tag.get('href', None)
        if ( href is None ) : continue
        # Resolve relative references like href="/contact"
        up = urlparse(href)
        if ( len(up.scheme) < 1 ) :
            href = urljoin(url, href)
        ipos = href.find('#')
        if ( ipos > 1 ) : href = href[:ipos]
        if ( href.endswith('.png') or href.endswith('.jpg') or href.endswith('.gif') ) : continue
        if ( href.endswith('/') ) : href = href[:-1]
        # print href
        if ( len(href) < 1 ) : continue

		# Check if the URL is in any of the webs
        found = False
        for web in webs:
            if ( href.startswith(web) ) :
                found = True
                break
        if not found : continue

        cur.execute('INSERT OR IGNORE INTO Pages (url, html, new_rank) VALUES ( ?, NULL, 1.0 )', ( href, ) )
        count = count + 1
        conn.commit()

        cur.execute('SELECT id FROM Pages WHERE url=? LIMIT 1', ( href, ))
        try:
            row = cur.fetchone()
            toid = row[0]
        except:
            print('Could not retrieve id')
            continue
        # print fromid, toid
        cur.execute('INSERT OR IGNORE INTO Links (from_id, to_id) VALUES ( ?, ? )', ( fromid, toid ) )


    print(count)

cur.close()


import sqlite3

conn = sqlite3.connect('spider.sqlite')
cur = conn.cursor()

# Find the ids that send out page rank - we only are interested
# in pages in the SCC that have in and out links
cur.execute('''SELECT DISTINCT from_id FROM Links''')
from_ids = list()
for row in cur: 
    from_ids.append(row[0])

# Find the ids that receive page rank 
to_ids = list()
links = list()
cur.execute('''SELECT DISTINCT from_id, to_id FROM Links''')
for row in cur:
    from_id = row[0]
    to_id = row[1]
    if from_id == to_id : continue
    if from_id not in from_ids : continue
    if to_id not in from_ids : continue
    links.append(row)
    if to_id not in to_ids : to_ids.append(to_id)

# Get latest page ranks for strongly connected component
prev_ranks = dict()
for node in from_ids:
    cur.execute('''SELECT new_rank FROM Pages WHERE id = ?''', (node, ))
    row = cur.fetchone()
    prev_ranks[node] = row[0]

sval = input('How many iterations:')
many = 1
if ( len(sval) > 0 ) : many = int(sval)

# Sanity check
if len(prev_ranks) < 1 : 
    print("Nothing to page rank.  Check data.")
    quit()

# Lets do Page Rank in memory so it is really fast
for i in range(many):
    # print prev_ranks.items()[:5]
    next_ranks = dict();
    total = 0.0
    for (node, old_rank) in list(prev_ranks.items()):
        total = total + old_rank
        next_ranks[node] = 0.0
    # print total

    # Find the number of outbound links and sent the page rank down each
    for (node, old_rank) in list(prev_ranks.items()):
        # print node, old_rank
        give_ids = list()
        for (from_id, to_id) in links:
            if from_id != node : continue
           #  print '   ',from_id,to_id

            if to_id not in to_ids: continue
            give_ids.append(to_id)
        if ( len(give_ids) < 1 ) : continue
        amount = old_rank / len(give_ids)
        # print node, old_rank,amount, give_ids
    
        for id in give_ids:
            next_ranks[id] = next_ranks[id] + amount
    
    newtot = 0
    for (node, next_rank) in list(next_ranks.items()):
        newtot = newtot + next_rank
    evap = (total - newtot) / len(next_ranks)

    # print newtot, evap
    for node in next_ranks:
        next_ranks[node] = next_ranks[node] + evap

    newtot = 0
    for (node, next_rank) in list(next_ranks.items()):
        newtot = newtot + next_rank

    # Compute the per-page average change from old rank to new rank
    # As indication of convergence of the algorithm
    totdiff = 0
    for (node, old_rank) in list(prev_ranks.items()):
        new_rank = next_ranks[node]
        diff = abs(old_rank-new_rank)
        totdiff = totdiff + diff

    avediff = totdiff / len(prev_ranks)
    print(i+1, avediff)

    # rotate
    prev_ranks = next_ranks

# Put the final ranks back into the database
print(list(next_ranks.items())[:5])
cur.execute('''UPDATE Pages SET old_rank=new_rank''')
for (id, new_rank) in list(next_ranks.items()) :
    cur.execute('''UPDATE Pages SET new_rank=? WHERE id=?''', (new_rank, id))
conn.commit()
cur.close()



import sqlite3

conn = sqlite3.connect('spider.sqlite')
cur = conn.cursor()

cur.execute('''SELECT COUNT(from_id) AS inbound, old_rank, new_rank, id, url 
     FROM Pages JOIN Links ON Pages.id = Links.to_id
     WHERE html IS NOT NULL
     GROUP BY id ORDER BY inbound DESC''')

count = 0
for row in cur :
    if count < 50 : print(row)
    count = count + 1
print(count, 'rows.')
cur.close()


import sqlite3

conn = sqlite3.connect('spider.sqlite')
cur = conn.cursor()

print("Creating JSON output on spider.js...")
howmany = int(input("How many nodes? "))

cur.execute('''SELECT COUNT(from_id) AS inbound, old_rank, new_rank, id, url 
    FROM Pages JOIN Links ON Pages.id = Links.to_id
    WHERE html IS NOT NULL AND ERROR IS NULL
    GROUP BY id ORDER BY id,inbound''')

fhand = open('spider.js','w')
nodes = list()
maxrank = None
minrank = None
for row in cur :
    nodes.append(row)
    rank = row[2]
    if maxrank is None or maxrank < rank: maxrank = rank
    if minrank is None or minrank > rank : minrank = rank
    if len(nodes) > howmany : break

if maxrank == minrank or maxrank is None or minrank is None:
    print("Error - please run sprank.py to compute page rank")
    quit()

fhand.write('spiderJson = {"nodes":[\n')
count = 0
map = dict()
ranks = dict()
for row in nodes :
    if count > 0 : fhand.write(',\n')
    # print row
    rank = row[2]
    rank = 19 * ( (rank - minrank) / (maxrank - minrank) ) 
    fhand.write('{'+'"weight":'+str(row[0])+',"rank":'+str(rank)+',')
    fhand.write(' "id":'+str(row[3])+', "url":"'+row[4]+'"}')
    map[row[3]] = count
    ranks[row[3]] = rank
    count = count + 1
fhand.write('],\n')

cur.execute('''SELECT DISTINCT from_id, to_id FROM Links''')
fhand.write('"links":[\n')

count = 0
for row in cur :
    # print row
    if row[0] not in map or row[1] not in map : continue
    if count > 0 : fhand.write(',\n')
    rank = ranks[row[0]]
    srank = 19 * ( (rank - minrank) / (maxrank - minrank) ) 
    fhand.write('{"source":'+str(map[row[0]])+',"target":'+str(map[row[1]])+',"value":3}')
    count = count + 1
fhand.write(']};')
fhand.close()
cur.close()

print("Open force.html in a browser to view the visualization")
